{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가위바위보 분류기 만들기\n",
    "## (Rock Scissor Paper Classifier)\n",
    "\n",
    "> ### **요약**\n",
    "> **train_data : 3000ea**  \n",
    "> **Validation_data : 300ea**  \n",
    "> **=> slack에 올라와있는 사진 3300장 중에 300장을 Validation_data로 사용하고, 나머지 3000장을 train_data로 사용하였다.  \n",
    "> [(해당 slack 페이지로 가기)](https://aiffel.slack.com/archives/C01HAK8SLLW/p1609832433416700)**   \n",
    "> **test_data : 300ea**  \n",
    "> **=> 윤선님이 제공해주신 test셋 사진 중 가위, 바위, 보 각 100장씩 총 300장을 뽑아 사용하였다.  \n",
    "> [(해당 slack 페이지로 가기)](https://aiffel.slack.com/archives/C01HAK8SLLW/p1609807863375800)**  \n",
    "> **`test acurracy : 75.6%`**  \n",
    "> **`번외test acurracy : 87.7%`**  \n",
    "  \n",
    "### - 분류기 모델 만들기\n",
    "\n",
    "***\n",
    "#### **1. 라이브러리 import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **2.1 train data 준비하기**\n",
    "- **가위 이미지**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **바위 이미지**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **보 이미지**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **train data 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3000 입니다.\n",
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=3000   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "\n",
    "# 데이터를 정규화시키기 위해 픽셀의 최소값 최대값을 확인\n",
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3000, 28, 28, 3)\n",
      "y_train shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train_norm.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train_norm[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **2.2 train model 설계하기**\n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea**  \n",
    "> **레이어별 특징 갯수**  \n",
    "> **_channel_1_ : 32**  \n",
    "> **_channel_2_ : 64**  \n",
    "> **_channel_3_ : 64**  \n",
    "> **dense 레이어 뉴런수 : 64**  \n",
    "> **학습 반복횟수(dense) : 40**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  9\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 60,675\n",
      "Trainable params: 60,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **train model 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0917 - accuracy: 0.3610\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9282 - accuracy: 0.5553\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6867 - accuracy: 0.7157\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7843\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8627\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2745 - accuracy: 0.9013\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.9253\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9490\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9697\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.9710\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9790\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.98 - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9847\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9810\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9830\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9957\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9877\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 0.9943\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9963\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9970\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9970\n",
      "94/94 - 0s - loss: 0.0105 - accuracy: 0.9993\n",
      "train_loss: 0.010477526113390923 \n",
      "train_accuracy: 0.9993333220481873\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# model 학습\n",
    "# 정규화된 data로 모델 학습\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "\n",
    "# 학습모델 시험\n",
    "# 정규화된 data로 모델 시험\n",
    "train_loss, train_accuracy = model.evaluate(x_train_norm, y_train, verbose=2)\n",
    "print(\"train_loss: {} \".format(train_loss))\n",
    "print(\"train_accuracy: {}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **학습결과**\n",
    "> **accuracy : 0.9993**  \n",
    "> **loss : 0.0105**  \n",
    "***  \n",
    "#### **3.1 validation data 준비하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/validation/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/validation/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/validation/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/validation/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/validation/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/validation/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **validation data 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증데이터(x_validation)의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "# train data와 흡사하게 코딩. 단 경로에 유의할 것\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"검증데이터(x_validation)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "# train data 경로가 아닌 validation 경로\n",
    "validationimage_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/validation\"\n",
    "(x_validation, y_validation)=load_data(validationimage_dir_path)\n",
    "x_validation_norm = x_validation/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **3.2 validation model 설계하기**\n",
    "> **1차  \n",
    "> 특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64  \n",
    "> dense 레이어 뉴런수 : 64  \n",
    "> 학습 반복횟수(dense) : 40**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 60,675\n",
      "Trainable params: 60,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0600 - accuracy: 0.4430\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7870 - accuracy: 0.6650\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.7700\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8440\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2933 - accuracy: 0.8970\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2373 - accuracy: 0.9247\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.9360\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1244 - accuracy: 0.9647\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9727\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9767\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9850\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9770\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9860\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9727\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9960\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9970\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 0.9977\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9967\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9770\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9943\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9977\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9990\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9983\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9987\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 0.9997\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9997\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9863\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9703\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9920\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9990\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9993\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9997\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 0.9987\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 0.9993\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 0.9997\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 9.4897e-04 - accuracy: 1.0000\n",
      "10/10 - 2s - loss: 3.6640 - accuracy: 0.6233\n",
      "validation_loss: 3.6640233993530273 \n",
      "validation_accuracy: 0.6233333349227905\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=64\n",
    "n_train_epoch=40\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation_norm, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **1차 검증결과**\n",
    "> **accuracy : 0.6233**  \n",
    "> **loss : 3.6640**  \n",
    "\n",
    "***   \n",
    "* **2차 설계**\n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 32  \n",
    "> _channel_3_ : 32  \n",
    "> dense 레이어 뉴런수 : 64  \n",
    "> 학습 반복횟수(dense) : 40** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 21,699\n",
      "Trainable params: 21,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0909 - accuracy: 0.3760\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9442 - accuracy: 0.5633\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7261 - accuracy: 0.6910\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7770\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8250\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.8727\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2734 - accuracy: 0.9047\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.9240\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9293\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1465 - accuracy: 0.9510\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9660\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0898 - accuracy: 0.9720\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9827\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0812 - accuracy: 0.9737\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0759 - accuracy: 0.9753\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9807\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9910\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9930\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9853\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9927\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9937\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9883\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9767\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9813\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 0.9927\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9970\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 0.9987\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9997\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0074 - accuracy: 0.9993\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9960\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9983\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9993\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9977\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9997\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9993\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9740\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9853\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9940\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 0.9987\n",
      "10/10 - 0s - loss: 3.7487 - accuracy: 0.5467\n",
      "validation_loss: 3.748677968978882 \n",
      "validation_accuracy: 0.54666668176651\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=64\n",
    "n_train_epoch=40\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation_norm, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **2차 검증결과**\n",
    "> **accuracy : 0.5467**  \n",
    "> **loss : 3.7487**  \n",
    "> **accuracy 감소, loss 증가**\n",
    "\n",
    "***   \n",
    "* **3차 설계** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 16  \n",
    "> _channel_2_ : 16  \n",
    "> _channel_3_ : 16  \n",
    "> dense 레이어 뉴런수 : 64  \n",
    "> 학습 반복횟수(dense) : 40** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 11, 11, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 3, 3, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 6,371\n",
      "Trainable params: 6,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 5s 58ms/step - loss: 1.0984 - accuracy: 0.3707\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0359 - accuracy: 0.4713\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8625 - accuracy: 0.6147\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7246 - accuracy: 0.6953\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.7437\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7780\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8147\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8297\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3946 - accuracy: 0.8503\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3511 - accuracy: 0.8713\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8757\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.9053\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2535 - accuracy: 0.9080\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9157\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9310\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1773 - accuracy: 0.9413\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9450\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.9347\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.9597\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1223 - accuracy: 0.9600\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9633\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9593\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9690\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9773\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9657\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9650\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9833\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0619 - accuracy: 0.9827\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9683\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9893\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9833\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9877\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9867\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9910\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9903\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9927\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9943\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9980\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9940\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1177 - accuracy: 0.9653\n",
      "10/10 - 2s - loss: 3.4109 - accuracy: 0.5433\n",
      "validation_loss: 3.4109292030334473 \n",
      "validation_accuracy: 0.5433333516120911\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=16\n",
    "n_channel_2=16\n",
    "n_channel_3=16\n",
    "n_dense=64\n",
    "n_train_epoch=40\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation_norm, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **3차 검증결과**\n",
    "> **accuracy : 0.5433**  \n",
    "> **loss : 3.4109**  \n",
    "> **accuracy 감소, loss 감소**\n",
    "\n",
    "***   \n",
    "* **4차 설계** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 32  \n",
    "> _channel_3_ : 32  \n",
    "> 정확도가 높이나온 특징갯수로 선정\n",
    "> dense 레이어 뉴런수 : 64  \n",
    "> 학습 반복횟수(dense) : 30 \n",
    "> 반복횟수 감소**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 21,699\n",
      "Trainable params: 21,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0931 - accuracy: 0.3777\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9818 - accuracy: 0.5207\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7652 - accuracy: 0.6690\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.7567\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7947\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4335 - accuracy: 0.8323\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8703\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.8900\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2562 - accuracy: 0.9013\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.9343\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1723 - accuracy: 0.9413\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9563\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9623\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9707\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9753\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0766 - accuracy: 0.9773\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9753\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9830\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9737\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9823\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9910\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9927\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9930\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9727\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9887\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 0.9953\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9993\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9987\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9993\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0131 - accuracy: 0.9977\n",
      "10/10 - 0s - loss: 2.5309 - accuracy: 0.5933\n",
      "validation_loss: 2.5309412479400635 \n",
      "validation_accuracy: 0.5933333039283752\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=64\n",
    "n_train_epoch=30\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation_norm, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **4차 검증결과**\n",
    "> **accuracy : 0.5933**  \n",
    "> **loss : 2.5309**  \n",
    "> **accuracy 증가, loss 감소**\n",
    "\n",
    "***   \n",
    "* **5차 설계** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 32  \n",
    "> _channel_3_ : 32    \n",
    "> dense 레이어 뉴런수 : 64  \n",
    "> 학습 반복횟수(dense) : 20** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 21,699\n",
      "Trainable params: 21,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0955 - accuracy: 0.3623\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9919 - accuracy: 0.4993\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7878 - accuracy: 0.6537\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6370 - accuracy: 0.7373\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8003\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3919 - accuracy: 0.8533\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2931 - accuracy: 0.8930\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.9203\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9373\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9423\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1330 - accuracy: 0.9553\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9700\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9713\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9777\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9777\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9890\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9807\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9770\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9833\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9827\n",
      "10/10 - 0s - loss: 2.7086 - accuracy: 0.6133\n",
      "validation_loss: 2.708556652069092 \n",
      "validation_accuracy: 0.6133333444595337\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation_norm, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **5차 검증결과**\n",
    "> **accuracy : 0.6133**  \n",
    "> **loss : 2.7086**  \n",
    "> **accuracy 증가, loss 증가**\n",
    "\n",
    "***   \n",
    "* **6차 설계** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 64  \n",
    "> _channel_2_ : 32  \n",
    "> _channel_3_ : 32    \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 11, 11, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 34,115\n",
      "Trainable params: 34,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0952 - accuracy: 0.3633\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0279 - accuracy: 0.4437\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8931 - accuracy: 0.5567\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7916 - accuracy: 0.6340\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.7087\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7800\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.8203\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.8657\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.9010\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.9150\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9187\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9363\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9507\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9610\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9553\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9693\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0822 - accuracy: 0.9737\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9773\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9783\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9723\n",
      "10/10 - 0s - loss: 2.2834 - accuracy: 0.6333\n",
      "validation_loss: 2.28336238861084 \n",
      "validation_accuracy: 0.6333333253860474\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=64\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=128\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation_norm, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **6차 검증결과**\n",
    "> **accuracy : 0.6333**  \n",
    "> **loss : 2.2834**  \n",
    "> **accuracy 증가, loss 감소**\n",
    "\n",
    "***   \n",
    "* **7차 설계** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64    \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_165 (Conv2D)          (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_165 (MaxPoolin (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_166 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_166 (MaxPoolin (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_167 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_167 (MaxPoolin (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_55 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 125)               8125      \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 3)                 378       \n",
      "=================================================================\n",
      "Total params: 64,823\n",
      "Trainable params: 64,823\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0815 - accuracy: 0.3947\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8145 - accuracy: 0.6210\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7647\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3976 - accuracy: 0.8477\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2644 - accuracy: 0.9083\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9323\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9503\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9680\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0734 - accuracy: 0.9763\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9737\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9777\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9927\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9783\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9803\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9940\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 0.9960\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9983\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9973\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9973\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 0.9983\n",
      "10/10 - 0s - loss: 2.2792 - accuracy: 0.6533\n",
      "validation_loss: 2.279188871383667 \n",
      "validation_accuracy: 0.653333306312561\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=125\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation_norm, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **7차 검증결과**\n",
    "> **accuracy : 0.6533**  \n",
    "> **loss : 2.2792**  \n",
    "> **accuracy 증가, loss 증가**\n",
    "> **최종 파라미터 확정**\n",
    "\n",
    "***   \n",
    "* **최종 파라미터** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64    \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20** \n",
    "\n",
    "***\n",
    "#### **4.1 test data 준비하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/test/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/test/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/test/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **test data 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# train data와 흡사하게 코딩. 단 경로에 유의할 것\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "# train data 경로가 아닌 test 경로\n",
    "testimage_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(testimage_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **4.2 test model 설계하기**\n",
    "* **최종 파라미터** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64    \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 65,027\n",
      "Trainable params: 65,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0814 - accuracy: 0.3823\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9115 - accuracy: 0.5743\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7298 - accuracy: 0.6747\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5600 - accuracy: 0.7643\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8270\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3142 - accuracy: 0.8827\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8987\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9257\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9533\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1077 - accuracy: 0.9693\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9687\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9720\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9867\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9813\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9873\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9787\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9827\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9880\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9910\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9953\n",
      "10/10 - 0s - loss: 1.4422 - accuracy: 0.7567\n",
      "test_loss: 1.442193865776062 \n",
      "test_accuracy: 0.7566666603088379\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=128\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train_norm, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **최종 테스트결과**\n",
    "> **accuracy : 0.7567**  \n",
    "> **loss : 1.4422**  \n",
    "\n",
    "***\n",
    "\n",
    "#### **5.1 번외 model 설계하기**\n",
    "> **목표 : 정돈된 data가 정확도값에 어떤 영향을 끼치는지 확인**  \n",
    "> **train data : slack에 윤선님이 올려주신 data로 학습.**  \n",
    "> **test data : 위의 testdata와 동일.**  \n",
    "\n",
    "- **번외 train data 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/new/Nscissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/new/Nrock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/new/Npaper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/new/Nscissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/new/Nrock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/new/Npaper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번외학습데이터(x_Ntrain)의 이미지 개수는 2520 입니다.\n",
      "x_Ntrain shape: (2520, 28, 28, 3)\n",
      "y_Ntrain shape: (2520,)\n",
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train data와 흡사하게 코딩. 단 경로에 유의할 것\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=2520   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/Nscissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/Nrock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/Npaper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"번외학습데이터(x_Ntrain)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "# train data 경로가 아닌 test 경로\n",
    "Ntrainimage_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/new\"\n",
    "(x_Ntrain, y_Ntrain)=load_data(Ntrainimage_dir_path)\n",
    "x_Ntrain_norm = x_Ntrain/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print(\"x_Ntrain shape: {}\".format(x_Ntrain.shape))\n",
    "print(\"y_Ntrain shape: {}\".format(y_Ntrain.shape))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_Ntrain[0])\n",
    "print('라벨: ', y_Ntrain[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **번외 train model 설계**\n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64  \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20  \n",
    "> 기존 model의 최종 파라미터 입력**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 65,027\n",
      "Trainable params: 65,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.7452\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9746\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9940\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9972\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9988\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 9.8179e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 6.3050e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 4.9150e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 4.2387e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.9690e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.4837e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.9028e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.7593e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.4638e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3692e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2251e-04 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 9.7672e-05 - accuracy: 1.0000\n",
      "79/79 - 0s - loss: 8.5780e-05 - accuracy: 1.0000\n",
      "Ntrain_loss: 8.578018605476245e-05 \n",
      "Ntrain_accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=128\n",
    "n_Ntrain_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_Ntrain_norm, y_Ntrain, epochs=n_Ntrain_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "Ntrain_loss, Ntrain_accuracy = model.evaluate(x_Ntrain_norm, y_Ntrain, verbose=2)\n",
    "print(\"Ntrain_loss: {} \".format(Ntrain_loss))\n",
    "print(\"Ntrain_accuracy: {}\".format(Ntrain_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **번외 test model 설계**\n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64  \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20  \n",
    "> 기존 model의 최종 파라미터 입력**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_69 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_69 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 65,027\n",
      "Trainable params: 65,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.6638 - accuracy: 0.7119\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0706 - accuracy: 0.9893\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9933\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9976\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 7.4920e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 4.9098e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 3.7893e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 3.0223e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.5903e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.1549e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6424e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3903e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.1974e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.0590e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 9.5517e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 8.1273e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 7.2499e-05 - accuracy: 1.0000\n",
      "10/10 - 0s - loss: 0.6898 - accuracy: 0.8767\n",
      "test_loss: 0.6897715926170349 \n",
      "test_accuracy: 0.8766666650772095\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=128\n",
    "n_Ntrain_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_Ntrain_norm, y_Ntrain, epochs=n_Ntrain_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **번외 모델 테스트결과**\n",
    "> **accuracy : 0.8767**  \n",
    "> **loss : 0.6898**  \n",
    "    \n",
    "    \n",
    "***  \n",
    "    \n",
    "### - 결론\n",
    ">  **오버피팅을 미연에 방지하기 위해서 dataset자체를 크게 키웠고, 입력되는 값을 0~1이 되게끔 정규화 하였다.  \n",
    "> 그러나 오버피팅으로 인해 검증 시의 정확도가 학습 시에 비해 작게 나왔다.\n",
    "> 하이퍼 파라미터를 조정하여 정확도를 높였고, 검증 시 정확도가 최고로 높게 나온 하이퍼 파라미터를 테스트 시에 적용하였다.  \n",
    "> 테스트 시에도 정확도 75.6%가 나오는 것을 확인하였다.  \n",
    "> 그러나 배경색, 손모양 등의 data가 정확도에 영향을 끼치는지 확인필요하다고 느꼈다.  \n",
    "> 기존에 slack에 올라와있었던 배경이 흰색으로 통일되고, 손모양이 명확하게 보이는 data set을 활용하여 실험하기로 하였다.  \n",
    "> 모델에서 다른조건을 통일하기위해서 이전 테스트에서 75.6%의 정확도를 달성했던 모델의 파라미터를 동일하게 적용하였고,  \n",
    "> train dataset만 다르게 조정하여 학습시키고 테스트를 해보았다.  \n",
    "> 테스트 결과 87.7%의 정확도 달성였고, 이는 dataset의 중요도를 나타낸다고 생각하였다.**  \n",
    "\n",
    "***\n",
    "### - 회고록\n",
    "\n",
    "> **인생에서 처음 만들어보는 이미지 분류기였다.  \n",
    "> 비록 가위바위보였지만 이것만으로도 엄청 어렵게 느껴졌다.  \n",
    "> 코드도 하나도 이해가 가지않지않았다.  \n",
    "> 코드를 한줄씩 뜯어서 보아도 '아니 이게 왜 이거지? 이건 이건가?'의 연속이었다.  \n",
    "> 그렇게 천천히 고민하면서 복사붙여넣고, 오류나고, 고치고의 연속이었다.  \n",
    "> 처음 학습데이터를 가지고 분류모델을 돌렸을때 정확도가 1에 가깝게 나와서 끝났다고 생각했다.  \n",
    "> 그런데 검증데이터를 가지고 시험해보니 정확도가 말도 안되게 낮았다.  \n",
    "> 오버피팅이었던 것이다. 오버피팅을 막기위해 정규화도 진행했고, 데이터셋도 다양한 사람들에게 받았었는데 소용이 없었다.  \n",
    "> 결국 하이퍼 파라미터를 최대한 조절해서 정확도를 높이는 수밖에 없었다.  \n",
    "> 그래도 다행이었던건 정확도를 높이려고 파라미터들을 조절하면서, 어렵고 힘들었던 분류기 모델이 그나마 친숙해졌다는 것이다.  \n",
    "> (이부분을 노리고 만들어진 노드같이 느껴졌다.)  \n",
    "> 앞으로도 계속해서 오류나고 고치고의 반복일 것 같다.  \n",
    "> 그래도 천천히 하다보면 완성할수 있을것이라고 믿는다.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가위바위보 분류기 만들기\n",
    "## (Rock Scissor Paper Classifier)\n",
    "\n",
    "> ### **요약**\n",
    "> **train_data : 3000ea**  \n",
    "> **Validation_data : 300ea**  \n",
    "> **=> slack에 올라와있는 사진 3300장 중에 300장을 Validation_data로 사용하고, 나머지 3000장을 train_data로 사용하였다.  \n",
    "> [(해당 slack 페이지로 가기)](https://aiffel.slack.com/archives/C01HAK8SLLW/p1609832433416700)**   \n",
    "> **test_data : 300ea**  \n",
    "> **=> 윤선님이 제공해주신 test셋 사진 중 가위, 바위, 보 각 100장씩 총 300장을 뽑아 사용하였다.  \n",
    "> [(해당 slack 페이지로 가기)](https://aiffel.slack.com/archives/C01HAK8SLLW/p1609807863375800)**  \n",
    "> **`final acurracy : 66.0%`**  \n",
    "  \n",
    "### - 분류기 모델 만들기\n",
    "\n",
    "***\n",
    "#### **1. 라이브러리 import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **2.1 train data 준비하기**\n",
    "- **가위 이미지**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **바위 이미지**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **보 이미지**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **train data 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3000 입니다.\n",
      "최소값: 0  최대값: 255\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=3000   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "\n",
    "# 데이터를 정규화시키기 위해 픽셀의 최소값 최대값을 확인\n",
    "print('최소값:',np.min(x_train), ' 최대값:',np.max(x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (3000, 28, 28, 3)\n",
      "y_train shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **2.2 train model 설계하기**\n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea**  \n",
    "> **레이어별 특징 갯수**  \n",
    "> **_channel_1_ : 32**  \n",
    "> **_channel_2_ : 64**  \n",
    "> **_channel_3_ : 64**  \n",
    "> **dense 레이어 뉴런수 : 64**  \n",
    "> **학습 반복횟수(dense) : 40**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  9\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 60,675\n",
      "Trainable params: 60,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **train model 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 3.2307 - accuracy: 0.4433\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8452 - accuracy: 0.6250\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.7237\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7913\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4083 - accuracy: 0.8417\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8703\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2808 - accuracy: 0.8857\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2122 - accuracy: 0.9237\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9160\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9277\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1259 - accuracy: 0.9567\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9587\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9590\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0655 - accuracy: 0.9787\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9800\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9820\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9650\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2347 - accuracy: 0.9177\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9740\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9667\n",
      "94/94 - 0s - loss: 0.0398 - accuracy: 0.9877\n",
      "train_loss: 0.03975363075733185 \n",
      "train_accuracy: 0.987666666507721\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# model 학습\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "\n",
    "# 학습모델 시험\n",
    "train_loss, train_accuracy = model.evaluate(x_train, y_train, verbose=2)\n",
    "print(\"train_loss: {} \".format(train_loss))\n",
    "print(\"train_accuracy: {}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **학습결과**\n",
    "> **accuracy : 0.9877**  \n",
    "> **loss : 0.0398**  \n",
    "***  \n",
    "#### **3.1 validation data 준비하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/validation/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/validation/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/validation/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/validation/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/validation/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/validation/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **validation data 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검증데이터(x_validation)의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "# train data와 흡사하게 코딩. 단 경로에 유의할 것\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"검증데이터(x_validation)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "# train data 경로가 아닌 validation 경로\n",
    "validationimage_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/validation\"\n",
    "(x_validation, y_validation)=load_data(validationimage_dir_path)\n",
    "x_validation_norm = x_validation/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **3.2 validation model 설계하기**\n",
    "> **1차  \n",
    "> 특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64  \n",
    "> dense 레이어 뉴런수 : 64  \n",
    "> 학습 반복횟수(dense) : 40**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 60,675\n",
      "Trainable params: 60,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.7441 - accuracy: 0.4437\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7445 - accuracy: 0.6690\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7733\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8350\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2788 - accuracy: 0.8983\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9040\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9433\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.9453\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9510\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2351 - accuracy: 0.9117\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9647\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9817\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9787\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0343 - accuracy: 0.9920\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9943\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1663 - accuracy: 0.9403\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9517\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9847\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9790\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9917\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9893\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9537\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9773\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0689 - accuracy: 0.9810\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1574 - accuracy: 0.9493\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9800\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0382 - accuracy: 0.9887\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9977\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9977\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9987\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0058 - accuracy: 0.9990\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9997\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 0.9993\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 0.9997\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 0.9990\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4573 - accuracy: 0.8520\n",
      "10/10 - 0s - loss: 2.2342 - accuracy: 0.4333\n",
      "validation_loss: 2.2341537475585938 \n",
      "validation_accuracy: 0.4333333373069763\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=64\n",
    "n_train_epoch=40\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **1차 검증결과**\n",
    "> **accuracy : 0.4333**  \n",
    "> **loss : 2.2342**  \n",
    "\n",
    "***   \n",
    "* **2차 설계**\n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 32  \n",
    "> _channel_3_ : 32  \n",
    "> dense 레이어 뉴런수 : 64  \n",
    "> 학습 반복횟수(dense) : 40** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 21,699\n",
      "Trainable params: 21,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.9541 - accuracy: 0.4530\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8291 - accuracy: 0.6197\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.7077\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7877\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8217\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8637\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.3371 - accuracy: 0.8697\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2333 - accuracy: 0.9117\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9237\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1773 - accuracy: 0.9353\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.9493\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1653 - accuracy: 0.9340\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9477\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.9443\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9830\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9810\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9817\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1222 - accuracy: 0.9530\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0926 - accuracy: 0.9663\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9700\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9687\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9597\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9693\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9537\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1188 - accuracy: 0.9590\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9843\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 0.9950\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 0.9967\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9973\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9977\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9977\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9987\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9963\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9967\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9983\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9987\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9997\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9990\n",
      "10/10 - 0s - loss: 4.4926 - accuracy: 0.5700\n",
      "validation_loss: 4.492642402648926 \n",
      "validation_accuracy: 0.5699999928474426\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=64\n",
    "n_train_epoch=40\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **2차 검증결과**\n",
    "> **accuracy : 0.5700**  \n",
    "> **loss : 4.4926**  \n",
    "> **accuracy 증가, loss 증가**\n",
    "\n",
    "***   \n",
    "* **3차 설계** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 16  \n",
    "> _channel_2_ : 16  \n",
    "> _channel_3_ : 16  \n",
    "> dense 레이어 뉴런수 : 64  \n",
    "> 학습 반복횟수(dense) : 40** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 11, 11, 16)        2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 3, 3, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                1088      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 6,371\n",
      "Trainable params: 6,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "94/94 [==============================] - 7s 75ms/step - loss: 1.6850 - accuracy: 0.4070\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.9410 - accuracy: 0.5597\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8376 - accuracy: 0.6070\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7277 - accuracy: 0.6647\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.6987\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.7403\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7590\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7890\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8233\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8360\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3563 - accuracy: 0.8543\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8690\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8877\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.9003\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2669 - accuracy: 0.8937\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2328 - accuracy: 0.9100\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.2559 - accuracy: 0.8980\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2010 - accuracy: 0.9277\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1500 - accuracy: 0.9467\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9350\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9557\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9413\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1576 - accuracy: 0.9400\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1530 - accuracy: 0.9413\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1413 - accuracy: 0.9433\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9483\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9593\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9700\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9697\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9737\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.9343\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9523\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9690\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0585 - accuracy: 0.9780\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1488 - accuracy: 0.9510\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9337\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1198 - accuracy: 0.9557\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9760\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0819 - accuracy: 0.9657\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1076 - accuracy: 0.9683\n",
      "10/10 - 3s - loss: 3.0458 - accuracy: 0.5100\n",
      "validation_loss: 3.0457828044891357 \n",
      "validation_accuracy: 0.5099999904632568\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=16\n",
    "n_channel_2=16\n",
    "n_channel_3=16\n",
    "n_dense=64\n",
    "n_train_epoch=40\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **3차 검증결과**\n",
    "> **accuracy : 0.5100**  \n",
    "> **loss : 3.0458**  \n",
    "> **accuracy 감소, loss 감소**\n",
    "\n",
    "***   \n",
    "* **4차 설계** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 32  \n",
    "> _channel_3_ : 32  \n",
    "> 정확도가 높이나온 특징갯수로 선정\n",
    "> dense 레이어 뉴런수 : 64  \n",
    "> 학습 반복횟수(dense) : 30 \n",
    "> 반복횟수 감소**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 21,699\n",
      "Trainable params: 21,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.2482 - accuracy: 0.4530\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8402 - accuracy: 0.6140\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6710 - accuracy: 0.7027\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7637\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8010\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8443\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8800\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8833\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2581 - accuracy: 0.8993\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2282 - accuracy: 0.9100\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1535 - accuracy: 0.9420\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9457\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1548 - accuracy: 0.9440\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9477\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.9557\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1217 - accuracy: 0.9563\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9660\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1275 - accuracy: 0.9547\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9653\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9590\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9760\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9843\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9883\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9930\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9900\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9887\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9460\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9567\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9887\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9953\n",
      "10/10 - 0s - loss: 3.4242 - accuracy: 0.5467\n",
      "validation_loss: 3.4241902828216553 \n",
      "validation_accuracy: 0.54666668176651\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=64\n",
    "n_train_epoch=30\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **4차 검증결과**\n",
    "> **accuracy : 0.5467**  \n",
    "> **loss : 3.4242**  \n",
    "> **accuracy 증가, loss 증가**\n",
    "\n",
    "***   \n",
    "* **5차 설계** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 32  \n",
    "> _channel_3_ : 32    \n",
    "> dense 레이어 뉴런수 : 64  \n",
    "> 학습 반복횟수(dense) : 20** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_31 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 21,699\n",
      "Trainable params: 21,699\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.7691 - accuracy: 0.4733\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7651 - accuracy: 0.6683\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7537\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8250\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3850 - accuracy: 0.8397\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2737 - accuracy: 0.8850\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.9290\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.9323\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1344 - accuracy: 0.9593\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1098 - accuracy: 0.9647\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.9410\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1169 - accuracy: 0.9573\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9753\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9737\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9603\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9883\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9640\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2012 - accuracy: 0.9337\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9797\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9877\n",
      "10/10 - 0s - loss: 2.8762 - accuracy: 0.5300\n",
      "validation_loss: 2.876201868057251 \n",
      "validation_accuracy: 0.5299999713897705\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **5차 검증결과**\n",
    "> **accuracy : 0.5300**  \n",
    "> **loss : 2.8762**  \n",
    "> **accuracy 감소, loss 큰폭으로 감소**\n",
    "\n",
    "***   \n",
    "* **6차 설계** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 64  \n",
    "> _channel_2_ : 32  \n",
    "> _channel_3_ : 32    \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 11, 11, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 34,115\n",
      "Trainable params: 34,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 5s 51ms/step - loss: 1.4708 - accuracy: 0.4433\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8147 - accuracy: 0.6153\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.7133\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7653\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8050\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8563\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8940\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2393 - accuracy: 0.9070\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2067 - accuracy: 0.9197\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1972 - accuracy: 0.9237\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9197\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9530\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9600\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9670\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9323\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 0.9740\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1493 - accuracy: 0.9420\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9507\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1246 - accuracy: 0.9583\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9697\n",
      "10/10 - 2s - loss: 2.8080 - accuracy: 0.5700\n",
      "validation_loss: 2.807974338531494 \n",
      "validation_accuracy: 0.5699999928474426\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=64\n",
    "n_channel_2=32\n",
    "n_channel_3=32\n",
    "n_dense=128\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **6차 검증결과**\n",
    "> **accuracy : 0.5700**  \n",
    "> **loss : 2.8080**  \n",
    "> **accuracy 증가, loss 감소**\n",
    "\n",
    "***   \n",
    "* **7차 설계** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64    \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_82 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 65,027\n",
      "Trainable params: 65,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.7836 - accuracy: 0.4770\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7090 - accuracy: 0.6800\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7767\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.8163\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2755 - accuracy: 0.8863\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2689 - accuracy: 0.8867\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2229 - accuracy: 0.9170\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9270\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9393\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1626 - accuracy: 0.9387\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9527\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9600\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9667\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9793\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9777\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9597\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.9877\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1912 - accuracy: 0.9357\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9433\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9860\n",
      "10/10 - 0s - loss: 1.9653 - accuracy: 0.6767\n",
      "validation_loss: 1.9653023481369019 \n",
      "validation_accuracy: 0.6766666769981384\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=128\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "validation_loss, validation_accuracy = model.evaluate(x_validation, y_validation, verbose=2)\n",
    "print(\"validation_loss: {} \".format(validation_loss))\n",
    "print(\"validation_accuracy: {}\".format(validation_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **7차 검증결과**\n",
    "> **accuracy : 0.6767**  \n",
    "> **loss : 1.9653**  \n",
    "> **accuracy 증가, loss 감소**\n",
    "> **최종 파라미터 확정**\n",
    "\n",
    "***   \n",
    "* **최종 파라미터** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64    \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20** \n",
    "\n",
    "***\n",
    "#### **4.1 test data 준비하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/test/scissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/test/rock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/test/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **test data 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# train data와 흡사하게 코딩. 단 경로에 유의할 것\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "# train data 경로가 아닌 test 경로\n",
    "testimage_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(testimage_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### **4.2 test model 설계하기**\n",
    "* **최종 파라미터** \n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64    \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_85 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_86 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 65,027\n",
      "Trainable params: 65,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.8379 - accuracy: 0.4293\n",
      "Epoch 2/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7958 - accuracy: 0.6533\n",
      "Epoch 3/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5601 - accuracy: 0.7603\n",
      "Epoch 4/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8573\n",
      "Epoch 5/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2733 - accuracy: 0.8963\n",
      "Epoch 6/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2201 - accuracy: 0.9197\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1520 - accuracy: 0.9487\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9487\n",
      "Epoch 9/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0711 - accuracy: 0.9787\n",
      "Epoch 10/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9697\n",
      "Epoch 11/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1412 - accuracy: 0.9450\n",
      "Epoch 12/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0609 - accuracy: 0.9833\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9873\n",
      "Epoch 14/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9923\n",
      "Epoch 15/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9943\n",
      "Epoch 16/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9963\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0101 - accuracy: 0.9977\n",
      "Epoch 18/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9960\n",
      "Epoch 19/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9960\n",
      "Epoch 20/20\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9960\n",
      "10/10 - 0s - loss: 3.6026 - accuracy: 0.6600\n",
      "test_loss: 3.6026484966278076 \n",
      "test_accuracy: 0.6600000262260437\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=128\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **최종 테스트결과**\n",
    "> **accuracy : 0.6600**  \n",
    "> **loss : 3.6026**  \n",
    "\n",
    "***\n",
    "\n",
    "#### **5.1 번외 model 설계하기**\n",
    "> **목표 : 정돈된 data가 정확도값에 어떤 영향을 끼치는지 확인**  \n",
    "> **train data : slack에 윤선님이 올려주신 data로 학습.**  \n",
    "> **test data : 위의 testdata와 동일.**  \n",
    "\n",
    "- **번외 train data 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/new/Nscissor\n",
      "가위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/new/Nrock\n",
      "바위 이미지 resize 완료!\n",
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/new/Npaper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/new/Nscissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/new/Nrock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "\n",
    "\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/new/Npaper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "번외학습데이터(x_Ntrain)의 이미지 개수는 2520 입니다.\n",
      "x_Ntrain shape: (2520, 28, 28, 3)\n",
      "y_Ntrain shape: (2520,)\n",
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train data와 흡사하게 코딩. 단 경로에 유의할 것\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=2520   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/Nscissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/Nrock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/Npaper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"번외학습데이터(x_Ntrain)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "# train data 경로가 아닌 test 경로\n",
    "Ntrainimage_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/new\"\n",
    "(x_Ntrain, y_Ntrain)=load_data(Ntrainimage_dir_path)\n",
    "x_Ntrain_norm = x_Ntrain/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print(\"x_Ntrain shape: {}\".format(x_Ntrain.shape))\n",
    "print(\"y_Ntrain shape: {}\".format(y_Ntrain.shape))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_Ntrain[0])\n",
    "print('라벨: ', y_Ntrain[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **번외 train model 설계**\n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64  \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20  \n",
    "> 기존 model의 최종 파라미터 입력**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 65,027\n",
      "Trainable params: 65,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3537 - accuracy: 0.7206\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0954 - accuracy: 0.9742\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0774 - accuracy: 0.9734\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0166 - accuracy: 0.9980\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0102 - accuracy: 0.9984\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 8.8171e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0332 - accuracy: 0.9885\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.1840 - accuracy: 0.9385\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 8.5662e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 3.5172e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.3112e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.8453e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 1.3339e-04 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 9.5403e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 7.3608e-05 - accuracy: 1.0000\n",
      "79/79 - 0s - loss: 6.1609e-05 - accuracy: 1.0000\n",
      "Ntrain_loss: 6.160879274830222e-05 \n",
      "Ntrain_accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=128\n",
    "n_Ntrain_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_Ntrain, y_Ntrain, epochs=n_Ntrain_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "Ntrain_loss, Ntrain_accuracy = model.evaluate(x_Ntrain, y_Ntrain, verbose=2)\n",
    "print(\"Ntrain_loss: {} \".format(Ntrain_loss))\n",
    "print(\"Ntrain_accuracy: {}\".format(Ntrain_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **번외 test model 설계**\n",
    "> **특징을 잡아낼 레이어 갯수 : 3ea  \n",
    "> 레이어별 특징 갯수  \n",
    "> _channel_1_ : 32  \n",
    "> _channel_2_ : 64  \n",
    "> _channel_3_ : 64  \n",
    "> dense 레이어 뉴런수 : 128  \n",
    "> 학습 반복횟수(dense) : 20  \n",
    "> 기존 model의 최종 파라미터 입력**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 65,027\n",
      "Trainable params: 65,027\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 2.7488 - accuracy: 0.6683\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.1184 - accuracy: 0.9734\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0247 - accuracy: 0.9972\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.0107 - accuracy: 0.9988\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 7.5867e-04 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 5.2705e-04 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 4.3091e-04 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 3.5537e-04 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.8741e-04 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 2.1416e-04 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.9157e-04 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.6030e-04 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.3373e-04 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.1793e-04 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 9.9185e-05 - accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 8.7462e-05 - accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 7.6292e-05 - accuracy: 1.0000\n",
      "10/10 - 0s - loss: 1.1292 - accuracy: 0.7733\n",
      "test_loss: 1.1292493343353271 \n",
      "test_accuracy: 0.7733333110809326\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=128\n",
    "n_Ntrain_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_Ntrain, y_Ntrain, epochs=n_Ntrain_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * **번외 모델 테스트결과**\n",
    "> **accuracy : 0.7733**  \n",
    "> **loss : 1.1292**  \n",
    "    \n",
    "    \n",
    "***  \n",
    "    \n",
    "### - 결론\n",
    ">  **오버피팅을 미연에 방지하기 위해서 dataset자체를 크게 키웠고, 입력되는 값을 0~1이 되게끔 정규화 하였다.  \n",
    "> 그러나 오버피팅으로 인해 검증 시의 정확도가 학습 시에 비해 작게 나왔다.  \n",
    "> 결국 하이퍼 파라미터를 조정하여 정확도를 높였고, 검증 시 정확도가 60% 이상이었던 하이퍼 파라미터를 테스트 시에 적용하였다.  \n",
    "> 테스트 시에도 정확도 66.0%가 나오는 것을 확인하였다.  \n",
    "> 그러나 배경색, 손모양 등의 data가 정확도에 영향을 끼치는지 확인필요하다고 느꼈다.  \n",
    "> 기존에 slack에 올라와있었던 배경이 흰색으로 통일되고, 손모양이 명확하게 보이는 data set을 활용하여 실험하기로 하였다.  \n",
    "> 모델에서 다른조건을 통일하기위해서 이전 테스트에서 66.0%의 정확도를 달성했던 모델의 파라미터를 동일하게 적용하였고,  \n",
    "> train dataset만 다르게 조정하여 학습시키고 테스트를 해보았다.  \n",
    "> 테스트 결과 77.3%의 정확도 달성였고, 이는 dataset의 중요도를 나타낸다고 생각하였다.**  \n",
    "\n",
    "***\n",
    "### - 회고록\n",
    "\n",
    "> **인생에서 처음 만들어보는 이미지 분류기였다.  \n",
    "> 비록 가위바위보였지만 이것만으로도 엄청 어렵게 느껴졌다.  \n",
    "> 코드도 하나도 이해가 가지않지않았다.  \n",
    "> 코드를 한줄씩 뜯어서 보아도 '아니 이게 왜 이거지? 이건 이건가?'의 연속이었다.  \n",
    "> 그렇게 천천히 고민하면서 복사붙여넣고, 오류나고, 고치고의 연속이었다.  \n",
    "> 처음 학습데이터를 가지고 분류모델을 돌렸을때 정확도가 1에 가깝게 나와서 끝났다고 생각했다.  \n",
    "> 그런데 검증데이터를 가지고 시험해보니 정확도가 말도 안되게 낮았다.  \n",
    "> 오버피팅이었던 것이다. 오버피팅을 막기위해 정규화도 진행했고, 데이터셋도 다양한 사람들에게 받았었는데 소용이 없었다.  \n",
    "> 결국 하이퍼 파라미터를 최대한 조절해서 정확도를 높이는 수밖에 없었다.  \n",
    "> 그래도 다행이었던건 정확도를 높이려고 파라미터들을 조절하면서, 어렵고 힘들었던 분류기 모델이 그나마 친숙해졌다는 것이다.  \n",
    "> (이부분을 노리고 만들어진 노드같이 느껴졌다.)  \n",
    "> 앞으로도 계속해서 오류나고 고치고의 반복일 것 같다.  \n",
    "> 그래도 천천히 하다보면 완성할수 있을것이라고 믿는다.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

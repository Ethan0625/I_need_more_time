{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3000 입니다.\n",
      "x_train shape: (3000, 28, 28, 3)\n",
      "y_train shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=3000   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  9\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 15,491\n",
      "Trainable params: 15,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "94/94 [==============================] - 9s 92ms/step - loss: 1.2242 - accuracy: 0.4617\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7814 - accuracy: 0.6577\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.5986 - accuracy: 0.7553\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.8280\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8707\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2530 - accuracy: 0.9143\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1861 - accuracy: 0.9370\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9403\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9533\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.9703\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9603\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0855 - accuracy: 0.9707\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0739 - accuracy: 0.9740\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9827\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9923\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9960\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9967\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9980\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9963\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9710\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9597\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.9673\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9573\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9850\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9967\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 0.9987\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 0.9990\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.9997\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9703\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9630\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9877\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0049 - accuracy: 0.9997\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9993\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0114 - accuracy: 0.9967\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0656 - accuracy: 0.9823\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0863 - accuracy: 0.9713\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb9b00a5610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "testimage_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(testimage_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 60,675\n",
      "Trainable params: 60,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 2.5373 - accuracy: 0.4783\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7571 - accuracy: 0.6643\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7613\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8310\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3113 - accuracy: 0.8800\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2743 - accuracy: 0.8973\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2093 - accuracy: 0.9247\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9397\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9427\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.9650\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9737\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9800\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9860\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9670\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1368 - accuracy: 0.9497\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9483\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9840\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9890\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9927\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9947\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9873\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9907\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 0.9577\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9617\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9427\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9637\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9817\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9847\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9910\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9980\n",
      "10/10 - 0s - loss: 4.3430 - accuracy: 0.6233\n",
      "test_loss: 4.3430070877075195 \n",
      "test_accuracy: 0.6233333349227905\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=64\n",
    "n_train_epoch=30\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "회고록\n",
    "인생에서 처음 만들어보는 이미지 분류기였다.\n",
    "비록 가위바위보였지만 이것만으로도 엄청 어렵게 느껴졌다.\n",
    "코드도 하나도 이해가 가지않지않았다.\n",
    "코드를 한줄씩 뜯어서 보아도 '아니 이게 왜 이거지? 이건 이건가?'의 연속이었다.\n",
    "그렇게 천천히 고민하면서 복사붙여넣고, 오류나고, 고치고의 연속이었다.\n",
    "앞으로도 계속해서 오류나고 고치고의 반복일 것같다.\n",
    "그래도 천천히 하다보면 완성할수 있을것이라고 믿는다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

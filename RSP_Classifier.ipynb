{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "# [[YOUR CODE]]\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "# [[YOUR CODE]]\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 3000 입니다.\n",
      "x_train shape: (3000, 28, 28, 3)\n",
      "y_train shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=3000   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWdUlEQVR4nO3dW2ydV5UH8P/6zsV2fJI4aS6kjaFtSKEF2rS4GYYixG2qUs2o8MCIaoQ6UjXhASSQeBjEPNDHajSA0AghhaGijBgQEiD6UAaqglTBCAYXMm1CoIVM2qRJk7S5OL7Ex+ecNQ8+jEzx/i9zrhb7/5Mi22d5f9/OZ69zbK9v7W3uDhH581cMewIiMhhKdpFMKNlFMqFkF8mEkl0kE+VBnmzD2KhPbKqlP8GMH4DErYuxAGAI4uzc/MzhsSOF8edkJ4dvBdUWK4K5lYJzB8cvsclFX7L4Eyg2t6gI5a0Wj/Ph4XXp5ths8hcuXMTc3NyqV6arZDezuwB8HkAJwL+5+4Ps8yc21XD/3/11+nglPp3SSCUZK8pVOrYopccCQLng8UqRnlulKNGxIwWfmzf4l3dkZITGW5X0+ReaS3SsjQXXbXyUxuutJo1vbqSfLIqCP5GUSvy6Rk/wS2Ru9cUGHVuv12m80eDjl5o8zp4LoicK9gT+r5//QjLW8Y/xZlYC8AUA7wVwE4B7zeymTo8nIv3Vze/s+wH81t2PuXsdwDcA3NObaYlIr3WT7NcAOLHi45Ptx/6AmR0ws2kzm55buNLF6USkG90k+2q/MP3RLxPuftDdp9x9anyM//4nIv3TTbKfBDC54uPdAE51Nx0R6Zdukv3nAPaa2XVmVgXwQQCP9GZaItJrHZfe3L1hZh8F8H0sl94ecvcjdAyAVjNdNjDjtU1jVZ6Cj0Vw7GYQL0j1sxSUSprOj724MM/Hg5e3amNbkrFqiZenZuZnaXypPkfj5QovWbbK4zTejaj01iSlt1ZQR+82HpXu+lV6Y2O7qrO7+6MAHu3mGCIyGLpdViQTSnaRTCjZRTKhZBfJhJJdJBNKdpFMDLSfvbACo6Mb0vFK0OJaTbd6WjDWyrweHLVTVkmLbCV4ztwwwm8TvmrLVhqP6sn1RrqNtRL0q2+/ahuNo8qvayNocR1ppq9r1OIaxSMFub+hoDdtxOeOWliDuz6CXnteZ2dRI/PWK7tIJpTsIplQsotkQskukgklu0gmlOwimRhs6a0oMDaWbnmMymcFK70FJaKwrBeU3ipk5dsqWXkWAFrBSqaVkWDu0ZrJRboYUw2WgrZq0KIalO6KYHzZ0/GopOjBucNlrEl1rVTwr0m5zL8m1eDclUqwojAZHy3/zV6j2fexXtlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXyYSSXSQTA62zL2/Cmz4liwFAwXZLDXZSDeNRPZrFg3pwqcrP3XDeblkN5r5lYnMyNjLK22svzFyi8fkrfMuu8c3pcwPAkqevW+ebGi8zRLu8khbXqL22HHy/tPjsq9Wgzs5ibJtr8Bo9u3dBr+wimVCyi2RCyS6SCSW7SCaU7CKZULKLZELJLpKJwdbZzVCqpHvSS10sB21BLTvqlS9X+Pgy6WePlmseHePn3rGZLyV94dxLNP7csd8lY9u3b6djt+3cQeP1Vo3HyTLWAGBlXudnwiWVo62NybbK9L4JAEWLf82ic9eX+HVhr7Pd/L8LUmfvKtnN7DiAywCaABruPtXN8USkf3rxyv5Od+cvPSIydPqdXSQT3Sa7A/iBmT1pZgdW+wQzO2Bm02Y2PTc33+XpRKRT3f4Yf4e7nzKzHQAeM7Nfu/sTKz/B3Q8COAgAk9dc3W3vg4h0qKtXdnc/1X57FsB3AOzvxaREpPc6TnYzGzezjb9/H8CdAA73amIi0lvd/Bi/E8B32v2zZQD/4e7/yQYURbBlc7D2u42me4SjnnFUgvXPgzr7KOlvjvrNR4Le56XFBRo/9fxzNH7iueeTsdHg/oLJ3VfTeJn0owOAL9VpvLoh/fXupk6+lvFNsmVztDR7N9smA0BxhV+XbrZsbpKzsy2bO052dz8G4JZOx4vIYKn0JpIJJbtIJpTsIplQsotkQskukomBLyVdlEibKmkjBfjyv9HSwFFLYznaspmU16pBi+uubdto/PCTv6TxF06mS2sAcOPr9iZjb30Lv89p7gov+116mS81vXtyN42/uNB5iSn6mkWlObS6aCPlR0b0Olli+0UH52elNQAotdj3m5aSFsmekl0kE0p2kUwo2UUyoWQXyYSSXSQTSnaRTAy0zm6FwarpOns5anEtpWuIUd20HBROR4M6+yip+VqwbPDCRV6rPvfCKRqvVfj2v7fdfHMyNj87R8eOjI7ReLT18Pe+9z0aXxhNb+m8f/9f0LEbN26k8ZmZGRofG0svY90MavQLC4s0vmEDv25s62QAWGql6/BLdV6jb5GtqNlp9coukgklu0gmlOwimVCyi2RCyS6SCSW7SCaU7CKZGHA/O+jTiwe1yRFS8x3dkK7fA0DQco6S8dpmjWwXPbExXUsGgOeeeYbGX3rhBRp/zzvfQ+M7JtJbPl+YnaVjjxw5QuM//tl/03jd+XW7/V3vTcbGxnitOrp3IlrDoFxJf82KoBW+Xm90de4iWMK7tER67cv8m5Utkc0K7XplF8mEkl0kE0p2kUwo2UUyoWQXyYSSXSQTSnaRTAy2zm6GMqmVV0b4dMplUpsk/cEAUCFbLgPAWLBmvS2mt+CducD7qo9OH6LxfXtvpPG3B33fP/lpuhb+00P83JfqvG978rrrafzmN99K46Va+h6ADWQ7ZwBYXORzK5X516xaTfezNxq8jl4hNXogrqNXnNfKDeT8wU0h1iRbNnezbryZPWRmZ83s8IrHtprZY2b2bPvtlug4IjJca/kx/isA7nrFY58E8Li77wXwePtjEVnHwmR39ycAnH/Fw/cAeLj9/sMA3tfbaYlIr3X6B7qd7n4aANpvd6Q+0cwOmNm0mU3PBvdpi0j/9P2v8e5+0N2n3H2qVqv1+3QiktBpsp8xs10A0H57tndTEpF+6DTZHwFwX/v9+wB8tzfTEZF+CevsZvZ1AO8AsM3MTgL4NIAHAXzTzO4H8DyAD6zpbMbPWK5E+3Gna5OthXQdHAC2TEzQ+M5gjfJLp19Mxv73V7+mY212nsavnuCVyye+/0Ma/+F//SQZa42N0LE3/+Vbafxtd/Je+oUmv7/hSjNd9y0Fa/UXQS18ZIT3w7PjR3V2C+7LKBW8Dh/1pLMyvBvPAyNrL7D16sNkd/d7E6F3R2NFZP3Q7bIimVCyi2RCyS6SCSW7SCaU7CKZGHCLKwBS0Wi0+NbHVVJKmRjnpbMtQTtlQVpYAaA5k77Vt1zn835VbRONXzrF70l68fxFGr/91tuSsWvJds4AsPuNN9H4DCl3AsDZixdpfGLz9mSs1Qq22S7z7aIrlWB9cKIJfu6otBaVDVvBltAlpI/fCvKAYaU3vbKLZELJLpIJJbtIJpTsIplQsotkQskukgklu0gmBlpnL4oC1fF0y2UzWDq4UknXNmsbeLvj/MVLNH4s2FZ57nS6Fl5zXnMF7wLFzJmXaPy1e15L41tePZmMWcG/xFE75fGTp2l88oY9ND5/vvOlyMIW2GDb5MVGul5dGL8uQZk9VAQtskUjXYeP/t/OlpomIb2yi2RCyS6SCSW7SCaU7CKZULKLZELJLpIJJbtIJgbbzw6AtNuiWuXTaTbTddNTJ07SseePP0fjZ595lsZbZFvmjcaLsqMF78s+//JFGp9b5D3lrRMnkrGdb+D96htIjR4AxoIltheDJZlZzdg96CmP6s3BeBavkq3DAd4XDgCLS3z9g1IpWGra09ct/n+xuamfXSR7SnaRTCjZRTKhZBfJhJJdJBNKdpFMKNlFMjHQOnuz1cTs/FwyvmVjjY5fJD3px351hI69RGrRAFBb5E3nTtaGP3n6FB27NMv79FusCRlAK1g/fc/ttydjN9xwAx1br/N68TWv3k3jz790jsZ3jKS/ptG2yZGoHs10W2e/Uudf06jXnt1DEK05X5D/Npt2+MpuZg+Z2VkzO7zisQfM7AUzO9T+d3d0HBEZrrX8GP8VAHet8vjn3H1f+9+jvZ2WiPRamOzu/gSA8wOYi4j0UTd/oPuomT3V/jF/S+qTzOyAmU2b2fTs5c7XIxOR7nSa7F8EsAfAPgCnAXwm9YnuftDdp9x9qhb8AU5E+qejZHf3M+7edPcWgC8B2N/baYlIr3WU7Ga2a8WH7wdwOPW5IrI+hHV2M/s6gHcA2GZmJwF8GsA7zGwfAAdwHMCH13KyaqOByZfTddkLv/4NHf/8744lY/PnLtKxmyt8Xfmixeuq52fTdfjZgu/9vvV1fG31c3P8bxkXX7WDxss3pteVb1y9k471jfy6nJh5mcYxzvu26VYAwdrtoYL3u5cr6eMvNXktO6rhV6ujNB7dQxDV0pkSvS8jHQuvtrvfu8rDX17DnERkHdHtsiKZULKLZELJLpIJJbtIJpTsIpkYaIvr/Pw8fvnLQ8l4c4mXK2YvXU7GGkEpBeAtic0rfPxiM116q47z8tWpsy/S+O69vA31ljveSuM33pReLnqsNk7HzjaDNtMWL0G1GjwetYoOSzftsb3Arkt0zTqdu17ZRTKhZBfJhJJdJBNKdpFMKNlFMqFkF8mEkl0kEwOtszcaTZw5l26ZbAV19sWF9LLHY2XecjhS5bXwVjOow5N2SZR5m+ctt+6j8TdNvZnGb9h3K43beLrF9sLcPB1bZ+sSAxgd5dfNgm22cYWHh6Xf9f9ujh+NpTV6Mk6v7CKZULKLZELJLpIJJbtIJpTsIplQsotkQskukonBbtncbGHmUrruW6vxHWNqExuTMW/wLZcvXgnqzUE//NXXX5uM3XDTG+jYW6emaHzzDr5UdDHGa93nZ9NLUc/WeaF7pJa+pgAwUuLfIuY87uBfl/Vq2P3u/aBXdpFMKNlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXycRA6+xWFCiPpnuvrzR4rXtuMV0rH9vAt03eed31NL51B9/aePI11yZj1+5Jb5kMAMU4v3/gYtDH32jM0LiTLuba+CY6tlwZofHWFV4nry/xOn5lhK8z0E+sVt5tHb2f4/tV4w9f2c1s0sx+ZGZHzeyImX2s/fhWM3vMzJ5tv93SlxmKSE+s5cf4BoBPuPuNAN4C4CNmdhOATwJ43N33Ani8/bGIrFNhsrv7aXf/Rfv9ywCOArgGwD0AHm5/2sMA3tenOYpID/xJf6Azs2sB3ArgZwB2uvtpYPkJAcCqN3ib2QEzmzaz6Sv1pS6nKyKdWnOym1kNwLcAfNzd+V+MVnD3g+4+5e5To1W+MKOI9M+akt3MKlhO9K+5+7fbD58xs13t+C4AZ/szRRHphbD0Zsvr1n4ZwFF3/+yK0CMA7gPwYPvtd+PTGWDpV/faJt5uWds0kYxd/ZpJOnbP619P4xPbr6LxlqWfFxdKJTp2ocl/fYk2my6X+ZdpbDS9LXO5XKVjm3Ve9muSraoBoNSn7YV7gZ271eJXPZp3P+NdjSXj1lJnvwPAhwA8bWaH2o99CstJ/k0zux/A8wA+sIZjiciQhMnu7j9Geu35d/d2OiLSL7pdViQTSnaRTCjZRTKhZBfJhJJdJBMDb3EdHUu3e95y2+10/Ovf9KZkrLyBt1JGte6Xr/Atm20k3Qo6vomfu9XkddNSUKf3gt95uNhK18oX5/j/uxSUwUcKXqevBttVzwX17H7qVy17LfFu6vhdHZuM1Su7SCaU7CKZULKLZELJLpIJJbtIJpTsIplQsotkYqB19s2bJ3Dn3X+TjG+c2EzHX5pNL1s8c/4CHTtCtnsGgLFtEzTOqtVnZ/nCPYXxy7wh2JK5GtTCS/X0J1Sc95uPlflS0mU+HL7I6/heGei32B+ee4h19si6XEpaRP48KNlFMqFkF8mEkl0kE0p2kUwo2UUyoWQXycRAi6AOoIV07/bM7AI/wEi6d7pSS6+dDgDNEn9euzTPtx42cm5Uec83Cn7uJeN11YJsyQwA5XL6+Nbgx15aCvrdg1Xtq8Ga9sNcN76fLFgvP1qjoCDfE9Fa/bSfncxLr+wimVCyi2RCyS6SCSW7SCaU7CKZULKLZELJLpKJtezPPgngqwBeheWtxA+6++fN7AEA/wDgXPtTP+Xuj7JjuQNLjc5qhACAZnqss+MCaJSC2mWZ71NuLTK3aF14cm/BWkQ95Q0ytyKYW1DShQe9+C26IzjQbAaTH5J+97OzOno0vqtzk9habqppAPiEu//CzDYCeNLMHmvHPufu/7KGY4jIkK1lf/bTAE63379sZkcBXNPviYlIb/1Jv7Ob2bUAbgXws/ZDHzWzp8zsITPbkhhzwMymzWx6ZvZyd7MVkY6tOdnNrAbgWwA+7u4zAL4IYA+AfVh+5f/MauPc/aC7T7n71KYaXwdORPpnTcluZhUsJ/rX3P3bAODuZ9y96e4tAF8CsL9/0xSRboXJbsvtPV8GcNTdP7vi8V0rPu39AA73fnoi0itr+Wv8HQA+BOBpMzvUfuxTAO41s31Y7lw9DuDD0YHcHfVGUOshjLUFlniJpxk8rXnQAsvihXe+PS8AFAWPN4LqVYmV3oIW1xIpZy6fm8ej/3uj0fmtHFEbaaSfS0l3i7WpRts9R/GUtfw1/sfAqg3VtKYuIuuL7qATyYSSXSQTSnaRTCjZRTKhZBfJhJJdJBODXUragTppRTXjzz3WInXToJ7cLActrkEx25ZYnM+7FSwF7cE9Aq2Ct9+2yH+tFbS4RiXbRsHnVgTjO60JA3/edXZ2/G6WkmbH1Su7SCaU7CKZULKLZELJLpIJJbtIJpTsIplQsotkwga5pa6ZnQPw3IqHtgF4aWAT+NOs17mt13kBmlunejm317j79tUCA032Pzq52bS7Tw1tAsR6ndt6nReguXVqUHPTj/EimVCyi2Ri2Ml+cMjnZ9br3NbrvADNrVMDmdtQf2cXkcEZ9iu7iAyIkl0kE0NJdjO7y8x+Y2a/NbNPDmMOKWZ23MyeNrNDZjY95Lk8ZGZnzezwise2mtljZvZs++2qe+wNaW4PmNkL7Wt3yMzuHtLcJs3sR2Z21MyOmNnH2o8P9dqReQ3kug38d3YzKwF4BsBfATgJ4OcA7nX3Xw10IglmdhzAlLsP/QYMM3s7gFkAX3X3N7Yf+2cA5939wfYT5RZ3/8d1MrcHAMwOexvv9m5Fu1ZuMw7gfQD+HkO8dmRef4sBXLdhvLLvB/Bbdz/m7nUA3wBwzxDmse65+xMAzr/i4XsAPNx+/2Esf7MMXGJu64K7n3b3X7Tfvwzg99uMD/XakXkNxDCS/RoAJ1Z8fBLra793B/ADM3vSzA4MezKr2Onup4Hlbx4AO4Y8n1cKt/EepFdsM75url0n2593axjJvtrCYuup/neHu98G4L0APtL+cVXWZk3beA/KKtuMrwudbn/erWEk+0kAkys+3g3g1BDmsSp3P9V+exbAd7D+tqI+8/sddNtvzw55Pv9vPW3jvdo241gH126Y258PI9l/DmCvmV1nZlUAHwTwyBDm8UfMbLz9hxOY2TiAO7H+tqJ+BMB97ffvA/DdIc7lD6yXbbxT24xjyNdu6Nufu/vA/wG4G8t/kf8dgH8axhwS87oewP+0/x0Z9twAfB3LP9YtYfknovsBXAXgcQDPtt9uXUdz+3cATwN4CsuJtWtIc3sbln81fArAofa/u4d97ci8BnLddLusSCZ0B51IJpTsIplQsotkQskukgklu0gmlOwimVCyi2Ti/wBzm1sNsuUMfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  9\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 15,491\n",
      "Trainable params: 15,491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "94/94 [==============================] - 5s 54ms/step - loss: 2.4223 - accuracy: 0.4400\n",
      "Epoch 2/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 1.0722 - accuracy: 0.5630\n",
      "Epoch 3/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.7179 - accuracy: 0.6900\n",
      "Epoch 4/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7707\n",
      "Epoch 5/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8040\n",
      "Epoch 6/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8483\n",
      "Epoch 7/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3213 - accuracy: 0.8827\n",
      "Epoch 8/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2870 - accuracy: 0.8827\n",
      "Epoch 9/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2372 - accuracy: 0.9140\n",
      "Epoch 10/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.9373\n",
      "Epoch 11/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1690 - accuracy: 0.9413\n",
      "Epoch 12/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9443\n",
      "Epoch 13/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1252 - accuracy: 0.9663\n",
      "Epoch 14/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9630\n",
      "Epoch 15/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1227 - accuracy: 0.9570\n",
      "Epoch 16/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0782 - accuracy: 0.9790\n",
      "Epoch 17/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9873\n",
      "Epoch 18/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9860\n",
      "Epoch 19/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9880\n",
      "Epoch 20/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9923\n",
      "Epoch 21/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.9950\n",
      "Epoch 22/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9920\n",
      "Epoch 23/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9957\n",
      "Epoch 24/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9977\n",
      "Epoch 25/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9983\n",
      "Epoch 26/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8433\n",
      "Epoch 27/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9537\n",
      "Epoch 28/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1289 - accuracy: 0.9503\n",
      "Epoch 29/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9673\n",
      "Epoch 30/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9910\n",
      "Epoch 31/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9950\n",
      "Epoch 32/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9957\n",
      "Epoch 33/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9977\n",
      "Epoch 34/40\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0139 - accuracy: 0.9973\n",
      "Epoch 35/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 0.9987\n",
      "Epoch 36/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.9973\n",
      "Epoch 37/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9990\n",
      "Epoch 38/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9980\n",
      "Epoch 39/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 40/40\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc014220610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "10/10 - 0s - loss: 3.4824 - accuracy: 0.5267\n",
      "test_loss: 3.482443332672119 \n",
      "test_accuracy: 0.5266666412353516\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "testimage_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(testimage_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_33 (Conv2D)           (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 60,675\n",
      "Trainable params: 60,675\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "94/94 [==============================] - 4s 43ms/step - loss: 3.6219 - accuracy: 0.4497\n",
      "Epoch 2/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.8227 - accuracy: 0.6327\n",
      "Epoch 3/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.7290\n",
      "Epoch 4/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8387\n",
      "Epoch 5/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8710\n",
      "Epoch 6/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.9113\n",
      "Epoch 7/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9423\n",
      "Epoch 8/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.1610 - accuracy: 0.9427\n",
      "Epoch 9/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9707\n",
      "Epoch 10/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0756 - accuracy: 0.9777\n",
      "Epoch 11/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9817\n",
      "Epoch 12/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9873\n",
      "Epoch 13/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9950\n",
      "Epoch 14/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9910\n",
      "Epoch 15/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0448 - accuracy: 0.9887\n",
      "Epoch 16/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9787\n",
      "Epoch 17/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9703\n",
      "Epoch 18/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9600\n",
      "Epoch 19/30\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 0.9933\n",
      "Epoch 20/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9950\n",
      "Epoch 21/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9977\n",
      "Epoch 22/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9987\n",
      "Epoch 23/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9993\n",
      "Epoch 24/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9883\n",
      "Epoch 25/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9643\n",
      "Epoch 26/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 0.9867\n",
      "Epoch 27/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9963\n",
      "Epoch 28/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9993\n",
      "Epoch 29/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 30/30\n",
      "94/94 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9987\n",
      "10/10 - 2s - loss: 2.5507 - accuracy: 0.6800\n",
      "test_loss: 2.5506625175476074 \n",
      "test_accuracy: 0.6800000071525574\n"
     ]
    }
   ],
   "source": [
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_channel_3=64\n",
    "n_dense=64\n",
    "n_train_epoch=30\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_3, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)\n",
    "\n",
    "# 모델 시험\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
